{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c1072d",
   "metadata": {},
   "source": [
    "#### Run All to Initialize Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43016451",
   "metadata": {},
   "source": [
    "#### Dashboard code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc34817",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import io\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP PATHS & DATA ---\n",
    "project_root = Path.cwd().parent\n",
    "model_dir = project_root / \"models\"\n",
    "data_dir = project_root / \"data\" / \"processed\" / \"resized224p\"\n",
    "class_names = sorted([f.name for f in data_dir.iterdir() if f.is_dir()])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- MODEL LOADER ---\n",
    "def load_selected_model(model_name, num_classes):\n",
    "    if \"resnet50\" in model_name:\n",
    "        model = models.resnet50()\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        target_layer = [model.layer4[-1]]\n",
    "    elif \"efficientnet_b0\" in model_name:\n",
    "        model = models.efficientnet_b0()\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "        target_layer = [model.features[-1]]\n",
    "    elif \"convnext_tiny\" in model_name:\n",
    "        model = models.convnext_tiny()\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "        target_layer = [model.features[-1]]\n",
    "    \n",
    "    path = model_dir / model_name\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return model.to(device).eval(), target_layer\n",
    "\n",
    "# --- 3. UI STYLING & WIDGETS ---\n",
    "header_style = {'description_width': 'initial'}\n",
    "layout_padding = widgets.Layout(margin='10px 0', width='400px')\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[f.name for f in model_dir.glob(\"*.pth\")],\n",
    "    description='Select Model',\n",
    "    style=header_style,\n",
    "    layout=layout_padding\n",
    ")\n",
    "\n",
    "# CHANGED: multiple=True\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='image/*', \n",
    "    multiple=True, \n",
    "    description='Upload Artwork(s)',\n",
    "    layout=layout_padding\n",
    ")\n",
    "\n",
    "file_status = widgets.HTML(\n",
    "    value=\"<span style='color: #7f8c8d;'>No files uploaded</span>\",\n",
    "    layout=widgets.Layout(margin='-5px 0 10px 0')\n",
    ")\n",
    "\n",
    "analyze_btn = widgets.Button(\n",
    "    description=\"Analyze All Paintings\", \n",
    "    button_style='success', \n",
    "    icon='search',\n",
    "    layout=widgets.Layout(width='400px', height='40px', margin='20px 0')\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "# --- LOGIC & OBSERVERS ---\n",
    "def update_status(change):\n",
    "    num_files = len(change['new'])\n",
    "    if num_files == 0:\n",
    "        file_status.value = \"<span style='color: #7f8c8d;'>No files uploaded</span>\"\n",
    "    elif num_files == 1:\n",
    "        fname = change['new'][0]['name']\n",
    "        file_status.value = f\"<span style='color: #27ae60;'>1 file uploaded: <b>{fname}</b></span>\"\n",
    "    else:\n",
    "        file_status.value = f\"<span style='color: #27ae60;'><b>{num_files} files</b> uploaded</span>\"\n",
    "\n",
    "file_upload.observe(update_status, names='value')\n",
    "\n",
    "def on_analyze_clicked(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if not file_upload.value:\n",
    "            display(widgets.HTML(\"<h4 style='color: #e74c3c;'>Please upload images first!</h4>\"))\n",
    "            return\n",
    "        \n",
    "        # Load Model once for all images\n",
    "        model, target_layers = load_selected_model(model_dropdown.value, len(class_names))\n",
    "        \n",
    "        # Preprocessing setup\n",
    "        transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "        norm_transform = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "        # --- LOOP THROUGH ALL UPLOADED FILES ---\n",
    "        for file_info in file_upload.value:\n",
    "            img_name = file_info['name']\n",
    "            img_bytes = file_info['content']\n",
    "            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "            \n",
    "            # Predict\n",
    "            input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(norm_transform(input_tensor))\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            top_probs, top_idxs = torch.topk(probs, 3)\n",
    "            best_idx = top_idxs[0][0].item()\n",
    "            best_artist = class_names[best_idx].replace('_', ' ')\n",
    "            best_conf = top_probs[0][0].item() * 100\n",
    "\n",
    "            # --- INDIVIDUAL RESULT DISPLAY ---\n",
    "            display(widgets.HTML(f\"\"\"\n",
    "                <hr style=\"border: 1px solid #eee; margin: 40px 0;\">\n",
    "                <div style=\"background-color: #2c3e50; color: white; padding: 15px; border-radius: 10px; text-align: center;\">\n",
    "                    <h2 style=\"margin: 0; font-size: 22px;\">File: {img_name}</h2>\n",
    "                    <h1 style=\"margin: 5px 0; font-size: 28px;\">Prediction: {best_artist}</h1>\n",
    "                    <p style=\"font-size: 16px; opacity: 0.9;\">Confidence: {best_conf:.2f}%</p>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "\n",
    "            # Grad-CAM\n",
    "            cam = GradCAM(model=model, target_layers=target_layers)\n",
    "            targets = [ClassifierOutputTarget(best_idx)]\n",
    "            grayscale_cam = cam(input_tensor=norm_transform(input_tensor), targets=targets)[0, :]\n",
    "            rgb_img = np.float32(img.resize((224, 224))) / 255\n",
    "            cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "            # Visualization\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            ax[0].imshow(img)\n",
    "            ax[0].set_title(\"Original\", fontsize=10)\n",
    "            ax[0].axis('off')\n",
    "            ax[1].imshow(cam_image)\n",
    "            ax[1].set_title(\"Explainability (Grad-CAM)\", fontsize=10)\n",
    "            ax[1].axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            # Probabilities\n",
    "            list_items = []\n",
    "            for i in range(3):\n",
    "                name = class_names[top_idxs[0][i].item()].replace('_', ' ')\n",
    "                score = top_probs[0][i].item() * 100\n",
    "                list_items.append(f\"<li><b>{name}</b>: {score:.1f}%</li>\")\n",
    "            \n",
    "            display(widgets.HTML(f\"<ul>{''.join(list_items)}</ul>\"))\n",
    "\n",
    "analyze_btn.on_click(on_analyze_clicked)\n",
    "\n",
    "# --- 5. RENDER DASHBOARD ---\n",
    "dashboard_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h2>ðŸŽ¨ Tim! (Art Classifier with Grad-Cam Explainability)</h2>\"),\n",
    "    model_dropdown, \n",
    "    file_upload, \n",
    "    file_status,\n",
    "    analyze_btn, \n",
    "    out\n",
    "], layout=widgets.Layout(align_items='center', padding='20px', border_radius='15px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fd7ef",
   "metadata": {},
   "source": [
    "# Display Tim's Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dashboard_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
